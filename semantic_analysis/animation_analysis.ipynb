{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4299a8d7",
   "metadata": {},
   "source": [
    "Code cleanup. Upon analyzing the code, it looks like\n",
    "1. repeated sentences\n",
    "2. There's some shit going on with emojis\n",
    "3. There are some words concatenated together, especially the last word of a sentence and the first word of the next sentence.\n",
    "We need to get rid of these things.\n",
    "Data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a28db6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ce12f1a",
   "metadata": {},
   "source": [
    "1. Find all files in all 'txt' directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e69378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import regex as re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729ac060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateListOfWords(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        print(lines)\n",
    "        strippedLines = [line.strip() for line in lines if line.strip()]\n",
    "        removedDuplicateLinesList = []\n",
    "        for index in range(len(strippedLines)-1):\n",
    "            if (strippedLines[index] != strippedLines[index+1]*2):\n",
    "                removedDuplicateLinesList.append(strippedLines[index])\n",
    "        listOfListOfWords = [line.split() for line in removedDuplicateLinesList]\n",
    "        cleanedListOfWords = flattenListAndCleanWords(listOfListOfWords)\n",
    "    return cleanedListOfWords\n",
    "\n",
    "def UCC_slLJZ4p4HOznMUcFn_2g_isAnAnomaly(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        print(lines)\n",
    "        strippedLines = [line.strip() for line in lines if line.strip()]\n",
    "        listOfListOfWords = [line.split() for line in strippedLines]\n",
    "        cleanedListOfWords = flattenListAndCleanWords(listOfListOfWords)\n",
    "    return cleanedListOfWords\n",
    "\n",
    "def flattenListAndCleanWords(listOfListOfWords):\n",
    "    cleanedListOfWords = []\n",
    "    for listOfWords in listOfListOfWords:\n",
    "        for words in listOfWords:\n",
    "            word = re.split('[?.\"(),!)]', words)\n",
    "            for wo in word:\n",
    "                if wo!='':\n",
    "                    cleanedListOfWords.append(wo)\n",
    "    return cleanedListOfWords\n",
    "\n",
    "def flattenList(list):\n",
    "    flat_list = [item for sublist in list for item in sublist]\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "# for channelId in glob.glob(\"*/*/\"):\n",
    "#     wordCloud = []\n",
    "#     for txtFilePath in glob.glob(channelId+\"/*.txt\"):\n",
    "#         wordCloud.append(generateListOfWords(txtFilePath))\n",
    "#     flattened = flattenList(wordCloud)\n",
    "#     print(channelId.split('/')[0], \": \", len(flattened), \"words total\")\n",
    "\n",
    "#     with open(channelId.split('/')[0]+\"wordCloud.txt\", 'w') as f:\n",
    "#         json.dump(flattened, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36dd2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCC-slLJZ4p4HOznMUcFn_2g/txt/BicR2IzVk18.txt\n",
      "[\"It's raining.Yeah! Yeah, it is.So are you gonna leave, dude? Because, it's 2 AM, and everybody else has gone home, so-The pizza is going to be cold.I-I-I'm sorry, pizza?Guaranteed 30 minutes, or it's free.Are you trying to tell me something?That's a guaranteed 30 years in therapy when I bite down into a cold slice of fresh pizza.Is this because I wouldn't play Twister with you?It's been 31 minutes. That's disappointment.Ｔｈａｔ'ｓ ｃｏｌｄ ｐｉｚｚａ.*Knock Knock Knock*Go ahead open it - No,I'll open it for you.Wow, uhh,Anchovies. That's a, that's a trope.Look againAnchovies and pineapple.Everything I touch turns to waste,everything I waste gets recycled.*Click*Get in the pizza van, Michael.Woah, woah, hey, hey, hey, what are you doing, put the gun down..The van Michael-GET IN THE VAN*Music playing through the radio*Y'know man I, *inhale*, hate this songLemme just, turn that off..You like the Bee Gee's Michael?Uh, not, particularly..Name one of their albums. Go aheadAny one of themI can't really...Parallel parking. Y'know how to parallel park?No I mean-Exactly.It's a myth, created by the CIA to trick us into chasing the elusive dream of attempting to perfect symmetry.We can't play God, Michael. God is the meter maid.AND YOUR TIME IS UP.Duh, I'm sorry, where are we going again?Oh, we're here.So, I mean, what exactly are we doing-Feeling limber, Michael?Really man, really? You brought me all the way out here in the middle of the night to play Twister?I knew it. I knew it!Go ahead Michael, spin the dial.No, I'm not spinning the dial.Spin. the dial, MichaelLeft foot to red. Are you happy?Look again.Yeah, how does that make you feel?That's what I thought, you little bitch. ˙\\u2006͜ʟ˙\"]\n",
      "UCC-slLJZ4p4HOznMUcFn_2g/txt/kxObFGMFSJo.txt\n",
      "['Yeah!Welcome back everybody!Today we got with us TheOdd1sOut.Its good to have you here. :TIts good to have you here James.Mmm...nuhh...* S T A R E *In the video..its good uh...* S T A R E * (Breathing)Its good to have...* S T A R E * (Breathing)* S T A R E * (Breathing)Its nice to have you here..* S T A R E * (More breathing)In-In the video..Being here..*Pats hand* uwuJames.Thanks for stopping by.*Happy music! :D*Captions done by: The Early Bird 2I hope you enjoyed it! :D:D']\n",
      "UCC-slLJZ4p4HOznMUcFn_2g :  415 words total\n"
     ]
    }
   ],
   "source": [
    "#something's wrong with UCC-slLJZ4p4HOznMUcFn_2g\n",
    "#because there's only one 'line'\n",
    "\n",
    "list = [\"UCC-slLJZ4p4HOznMUcFn_2g\"]\n",
    "for channelId in list:\n",
    "    wordCloud = []\n",
    "    for txtFilePath in glob.glob(channelId+\"/txt/*.txt\"):\n",
    "        print(txtFilePath)\n",
    "        wordCloud.append(UCC_slLJZ4p4HOznMUcFn_2g_isAnAnomaly(txtFilePath))\n",
    "    flattened = flattenList(wordCloud)\n",
    "    print(channelId.split('/')[0], \": \", len(flattened), \"words total\")\n",
    "\n",
    "    with open(channelId.split('/')[0]+\"wordCloud.txt\", 'w') as f:\n",
    "        json.dump(flattened, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135beda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "811149f64e05d2226278a2e375973a70398b68aeeea8a4c51891bf9fc1d57f5b"
  },
  "kernelspec": {
   "display_name": "Python [conda env:colorization]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
