{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb33737",
   "metadata": {},
   "source": [
    "Code cleanup. Need to \n",
    "1. remove repeated sentences due to vtt formatting\n",
    "2. some words are concatenated together (helloBut--> hello But, swimming in a pool.We--> swimming in a pool. We)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import regex as re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus.reader import *\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mplcursors\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cea599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "positive = ['positive', 'negative']\n",
    "bad_test=['bad', 'worse', 'worst']\n",
    "emojis=[':D', 'XD', ':p', ':(']\n",
    "slang = ['ffs', 'smh']\n",
    "\n",
    "negative = ['i tripped and fell and broke a bone', 'she misses home', 'ffs']\n",
    "positive = ['life is beautiful', \"that's so exciting\", \"i couldn't wish for anything better- this is perfect\"]\n",
    "neutral = ['i folded the clothes.', 'he checked the time']\n",
    "\n",
    "post_twenty_fourteen=['pog', 'hangry'] #2019, 2018, 2017\n",
    "boosterWords=['very nice', 'VERY nice', 'VERY NICE!']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "negative = ['i tripped and fell and broke a bone', 'she misses home', 'ffs']\n",
    "\n",
    "def sia_sentiment(listOfWords):\n",
    "    for sentence in listOfWords:\n",
    "        sid = SIA()\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        for k in sorted(ss)[:1]:\n",
    "            print('{0}: {1}'.format(sentence, ss[k]), end='')\n",
    "        print()\n",
    "\n",
    "sia_sentiment(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../channelHolisticInfo.json', 'r') as j:\n",
    "    channelHolisticInfo = json.loads(j.read())\n",
    "channelHolisticInfoDf = pd.DataFrame.from_dict(channelHolisticInfo)\n",
    "channelHolisticInfoDf.drop('60', inplace = True)\n",
    "channelHolisticInfoDf.index = range(len(channelHolisticInfoDf))\n",
    "channelHolisticInfoDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_CHANNEL_IDS = channelHolisticInfoDf['channelId'].tolist()\n",
    "LIST_OF_CHANNEL_NAMES = channelHolisticInfoDf['channelName'].tolist()\n",
    "LIST_OF_VIDEO_COUNT = channelHolisticInfoDf['videoCount'].tolist()\n",
    "print(len(LIST_OF_VIDEO_COUNT), len(LIST_OF_VIDEO_COUNT), len(LIST_OF_VIDEO_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf034e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateListOfSentences(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        strippedLines = [line.strip() for line in lines if line.strip()] \n",
    "        duplicatedLinesList = []\n",
    "        for index in range(len(strippedLines)):\n",
    "            duplicatedLinesList.append(strippedLines[index])\n",
    "    return [i for n, i in enumerate(duplicatedLinesList) if i not in duplicatedLinesList[:n]]\n",
    "# print(generateListOfSentences(\"UCAlxwHEm1bWWYoe5VCSQYEg/txt/_9KytbCHaXU.txt\"))\n",
    "\n",
    "def generateListOfWords(listOfSentences):\n",
    "    all_stopwords = list(stopwords.words('english'))\n",
    "    cleanedListOfWords = []\n",
    "    for words in listOfSentences:\n",
    "        word = re.split('[?.\"(),!) ]', words)\n",
    "        for wo in word:\n",
    "            if wo !='' and wo not in all_stopwords:\n",
    "                cleanedListOfWords.append(wo)\n",
    "    return cleanedListOfWords\n",
    "\n",
    "def flattenList(list):\n",
    "    flat_list = [item for sublist in list for item in sublist]\n",
    "    return flat_list\n",
    "\n",
    "#wordCloud[channelId] = all words from all .txt files with no stopwords\n",
    "#sentenceCloud[channelId] = all sentences from all .txt files.\n",
    "\n",
    "wordCloud = {}\n",
    "sentenceCloud = {}\n",
    "for channelId in LIST_OF_CHANNEL_IDS:\n",
    "    listOfSentences = []\n",
    "    listOfWords = []\n",
    "    print(channelId, \"has \", len(glob.glob(channelId+\"/txt/*.txt\")), \"files to process.\")\n",
    "    for txtFilePath in glob.glob(channelId+\"/txt/*.txt\"):\n",
    "        listOfSentences.append(generateListOfSentences(txtFilePath))\n",
    "    flattenedListOfSentences = flattenList(listOfSentences) #<--\n",
    "    flattendListOfWords = generateListOfWords(flattenedListOfSentences)\n",
    "\n",
    "    sentenceCloud[channelId.split('/')[0]] = flattenedListOfSentences\n",
    "    wordCloud[channelId.split('/')[0]] = flattendListOfWords\n",
    "    print(channelId.split('/')[0], \": \", len(flattenedListOfSentences), \"sentences total\")\n",
    "    print(channelId.split('/')[0], \": \", len(flattendListOfWords), \"words total\")\n",
    "\n",
    "    # with open(channelId.split('/')[0]+\"_wordCloud.txt\", 'w') as f:\n",
    "    #     json.dump(flattendListOfWords, f)\n",
    "    # with open(channelId.split('/')[0]+\"_sentenceCloud.txt\", 'w') as f:\n",
    "    #     json.dump(flattenedListOfSentences, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec14cc",
   "metadata": {},
   "source": [
    "# Holistically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2615b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General sentiment by words spoken by youtubers\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "sia = SIA()\n",
    "results = []\n",
    "\n",
    "print(len(wordCloud.keys()))\n",
    "for channelId in LIST_OF_CHANNEL_IDS:\n",
    "    for words in wordCloud[channelId]:\n",
    "        pol_score = sia.polarity_scores(words)\n",
    "        pol_score['words']=words\n",
    "        results.append(pol_score)\n",
    "pd.set_option('display.max_columns', None, 'max_colwidth', None)\n",
    "df = pd.DataFrame.from_records(results)\n",
    "df['label']=0\n",
    "df.loc[df['compound'] > 0.10, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.10, 'label'] = -1\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fix, ax = plt.subplots(figsize=(8,8))\n",
    "counts = df.label.value_counts(normalize=True)*100\n",
    "sns.barplot(x=counts.index, y=counts, ax=ax)\n",
    "ax.set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "ax.set_ylabel([\"Percentage\"])\n",
    "plt.show()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_negative = df.loc[df['label'] != 0]\n",
    "df_positive_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_positive_negative.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4719ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "counts = df_positive_negative.label.value_counts(normalize=True)*100\n",
    "sns.barplot(x=counts.index, y=counts, ax=ax)\n",
    "ax.set_xticklabels(['Neg', 'Pos'])\n",
    "ax.set_ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e226b0",
   "metadata": {},
   "source": [
    "Basically, compared to redditors, animation youtubers are more 'positive'.\n",
    "\n",
    "Which is honestly not that surprising. Redditors are among the most realistic people out there and youtubers are generally out there to 'entertain'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150a3b2a",
   "metadata": {},
   "source": [
    "# By channel and sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General sentiment by words spoken by youtubers\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "sia = SIA()\n",
    "results = []\n",
    "for channelId in LIST_OF_CHANNEL_IDS:\n",
    "    for sentence in sentenceCloud[channelId]:\n",
    "        pol_score = sia.polarity_scores(sentence)\n",
    "        pol_score['sentence']=sentence\n",
    "        results.append(pol_score)\n",
    "pd.set_option('display.max_columns', None, 'max_colwidth', None)\n",
    "df = pd.DataFrame.from_records(results)\n",
    "df['label']=0\n",
    "df.loc[df['compound'] > 0.10, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.10, 'label'] = -1\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fix, ax = plt.subplots(figsize=(8,8))\n",
    "counts = df.label.value_counts(normalize=True)*100\n",
    "sns.barplot(x=counts.index, y=counts, ax=ax)\n",
    "ax.set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "ax.set_ylabel([\"Percentage\"])\n",
    "plt.show()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ab176",
   "metadata": {},
   "source": [
    "# By channel by sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General sentiment by words spoken by youtubers\n",
    "from IPython.display import display\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "sia = SIA()\n",
    "channelId_to_sentencedf = {}\n",
    "\n",
    "for channelId in LIST_OF_CHANNEL_IDS:\n",
    "    results = []\n",
    "    for sentence in sentenceCloud[channelId]:\n",
    "        pol_score = sia.polarity_scores(sentence)\n",
    "        pol_score['sentence']=sentence\n",
    "        results.append(pol_score)\n",
    "    pd.set_option('display.max_columns', None, 'max_colwidth', None)\n",
    "    df = pd.DataFrame.from_records(results)\n",
    "    channelId_to_sentencedf[channelId] = df\n",
    "df['label']=0\n",
    "df.loc[df['compound'] > 0.10, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.10, 'label'] = -1\n",
    "\n",
    "for channelId in LIST_OF_CHANNEL_IDS[8:12]:\n",
    "    display(channelId_to_sentencedf[channelId][200:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d41c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_negative = df.loc[df['label'] != 0]\n",
    "df_positive_negative.head()\n",
    "\n",
    "channel_df = channelId_to_sentencedf['UCnsem444vdU1HhS0mb2wwTA']\n",
    "target_df = channel_df.loc[channel_df['compound'] > 0]\n",
    "target_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_pos_words = {}\n",
    "top_20_neg_words = {}\n",
    "scores= {}\n",
    "for channelId in LIST_OF_CHANNEL_IDS:\n",
    "    channel_df = channelId_to_sentencedf[channelId]\n",
    "    target_df = channel_df.loc[channel_df['compound'] > 0]\n",
    "    scores[channelId] = sum(target_df['compound'])/len(target_df)\n",
    "channelName_to_no_neutral_scores = {}\n",
    "for i in range(0, len(LIST_OF_CHANNEL_NAMES)):\n",
    "    channelName_to_no_neutral_scores[LIST_OF_CHANNEL_NAMES[i]] = list(scores.values())[i]\n",
    "\n",
    "avg_score=sum(channelName_to_no_neutral_scores.values())/len(LIST_OF_CHANNEL_NAMES)\n",
    "print(\"avg score =\", avg_score)\n",
    "print(sorted(channelName_to_no_neutral_scores.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae439afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_pos_words = {}\n",
    "top_20_neg_words = {}\n",
    "scores= {}\n",
    "for channelId in LIST_OF_CHANNEL_IDS:\n",
    "    target_df = channelId_to_sentencedf[channelId]\n",
    "    positive_words = list(target_df.loc[target_df['pos']==1].sentence)\n",
    "    positive_frequency = FreqDist(positive_words)\n",
    "    pos_freq = positive_frequency.most_common(20)\n",
    "    negative_words = list(target_df.loc[target_df['neg']==1].sentence)\n",
    "    negative_frequency = FreqDist(negative_words)\n",
    "    neg_freq = negative_frequency.most_common(20)\n",
    "    top_20_pos_words[channelId] = pos_freq\n",
    "    top_20_neg_words[channelId] = neg_freq\n",
    "    pos_words = [str(p) for p in pos_freq]\n",
    "    pos_words_str = ', '.join(pos_words)\n",
    "    neg_words = [str(n) for n in neg_freq]\n",
    "    neg_words_str = ', '.join(neg_words)\n",
    "    # generateWordCloud(pos_words_str, neg_words_str)\n",
    "    scores[channelId] = sum(target_df['compound'])/len(target_df)\n",
    "\n",
    "print(len(scores), len(LIST_OF_CHANNEL_NAMES))\n",
    "\n",
    "channelName_to_scores = {}\n",
    "for i in range(0, len(LIST_OF_CHANNEL_NAMES)):\n",
    "    channelName_to_scores[LIST_OF_CHANNEL_NAMES[i]] = list(scores.values())[i]\n",
    "\n",
    "avg_score=sum(channelName_to_scores.values())/len(LIST_OF_CHANNEL_NAMES)\n",
    "print(\"avg score =\", avg_score)\n",
    "print(sorted(channelName_to_scores.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_channelName_to_scores = dict(sorted(channelName_to_scores.items(), key=lambda item: item[1]))\n",
    "sctsdf = pd.DataFrame.from_dict({'channelName':sorted_channelName_to_scores.keys(), 'scores': sorted_channelName_to_scores.values()})\n",
    "sctsdf\n",
    "\n",
    "pd.DataFrame(sctsdf).to_csv(\"semantic_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb8406",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = \"Channel Name\"\n",
    "y_name = \"Positivity\"\n",
    "tooltip_name = \"positivity value\"\n",
    "\n",
    "x= sctsdf['channelName']\n",
    "y= sctsdf['scores']\n",
    "tt = sctsdf['scores']\n",
    "fig, ax = plt.subplots(1, figsize=(12,6))\n",
    "ax.set_title ('Semantic Scores of Each Channel')\n",
    "fig.canvas.manager.set_window_title ('My Window Title')\n",
    "sc = ax.scatter(x, y)\n",
    "# Plot the average line\n",
    "mean_x=np.arange(0,61,1)\n",
    "mean_y=[avg_score for i in np.zeros_like(x)]\n",
    "mean_line = ax.plot(mean_x,mean_y, label='Mean', linestyle='--')\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "cursor = mplcursors.cursor(sc, hover=True)\n",
    "\n",
    "plt.xlabel(x_name)\n",
    "plt.ylabel(y_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_files = []\n",
    "for channelId in LIST_OF_CHANNEL_IDS:\n",
    "    num_of_files.append(len(os.listdir(channelId+\"/txt/\")))\n",
    "\n",
    "cntvdf = pd.DataFrame.from_dict({'channelName':LIST_OF_CHANNEL_NAMES, 'number of transcripts collected': num_of_files, 'number of vids': LIST_OF_VIDEO_COUNT})\n",
    "\n",
    "cntvdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a71648",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = sum(cntvdf['number of transcripts collected'])/sum(cntvdf['number of vids'])\n",
    "print(representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ffdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff\n",
    "subsPerYearSinceFirstUpload = channelHolisticInfoDf['subscribersPerYearSinceFirstUpload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(channelHolisticInfoDf.channelName, channelHolisticInfoDf.subscribersPerYearSinceFirstUpload)\n",
    "sorted_channelName_to_rescaledSubs = dict(sorted(dict(zipped).items(), key=lambda item: item[1]))\n",
    "sctrs = pd.DataFrame.from_dict({'channelName': sorted_channelName_to_rescaledSubs.keys(), 'rescaledSubCount': sorted_channelName_to_rescaledSubs.values()})\n",
    "sctrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x_name = \"Channel\"\n",
    "y_name = \"rescaledSubCount\"\n",
    "tooltip_name = \"subCountPerYearSinceFirstUpload\"\n",
    "\n",
    "x= sctrs['channelName']\n",
    "y= sctrs['rescaledSubCount']\n",
    "y_log = [math.log(i) for i in sctrs['rescaledSubCount']]\n",
    "tt = sctrs['rescaledSubCount']\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,6))\n",
    "sc = ax.scatter(x, y)\n",
    "ax.set_title ('Rescaled Subscriber Counts')\n",
    "\n",
    "avg_rescaledSubcount= sum(y)/len(LIST_OF_CHANNEL_NAMES)\n",
    "# Plot the average line\n",
    "mean_x=np.arange(0,61,1)\n",
    "mean_y=[avg_rescaledSubcount for i in np.zeros_like(x)]\n",
    "mean_line = ax.plot(mean_x,mean_y, label='Mean', linestyle='--')\n",
    "# mean_line = ax.plot(mean_x, mean_y, label='Mean', linestyle='--')\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "cursor = mplcursors.cursor(sc, hover=True)\n",
    "\n",
    "plt.xlabel(x_name)\n",
    "plt.ylabel(y_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_df = pd.DataFrame.from_dict({'channelName': channelHolisticInfoDf['channelName'], 'rescaledSubCount': subsPerYearSinceFirstUpload, 'positivityScores': channelName_to_scores.values()})\n",
    "def generate_plot(semantic_df):\n",
    "    x_name = \"averageCompoundScore\"\n",
    "    y_name = \"rescaledSubCount\"\n",
    "\n",
    "    tooltip_name = \"channelName\"\n",
    "    x= semantic_df['positivityScores']\n",
    "    y= semantic_df['rescaledSubCount']\n",
    "\n",
    "    tt = semantic_df[tooltip_name]\n",
    "    fig, ax = plt.subplots(1, figsize=(12,6))\n",
    "    sc = ax.scatter(x, y)\n",
    "\n",
    "    avg_rescaledSubcount= sum(y)/len(LIST_OF_CHANNEL_NAMES)\n",
    "    # Plot the average line\n",
    "    mean_x=np.arange(0,33,1)\n",
    "    mean_y=[avg_rescaledSubcount for i in np.zeros_like(x)]\n",
    "    # mean_line = ax.plot(mean_x, mean_y, label='Mean', linestyle='--')\n",
    "\n",
    "    annot = ax.annotate(\"\", xy=(0,0), xytext=(20,20),textcoords=\"offset points\",\n",
    "                        bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                        arrowprops=dict(arrowstyle=\"->\"))\n",
    "    ax.set_title ('Rescaled Subscriber Counts v. Semantic Scores')\n",
    "\n",
    "    annot.set_visible(False)\n",
    "\n",
    "    def update_annot(details):\n",
    "        pos = sc.get_offsets()[details[\"channelName\"]]\n",
    "        annot.xy = pos\n",
    "        text = \"{}, {}\".format(\" \".join(details[\"channelName\"]), \n",
    "                            \" \".join([details[\"positivityScores\"]]))\n",
    "        annot.set_text(text)\n",
    "        annot.get_bbox_patch().set_alpha(0.4)\n",
    "\n",
    "    def hover(event):\n",
    "        vis = annot.get_visible()\n",
    "        if event.inaxes == ax:\n",
    "            cont, details = sc.contains(event)\n",
    "            if cont:\n",
    "                update_annot(details)\n",
    "                annot.set_visible(True)\n",
    "                fig.canvas.draw_idle()\n",
    "            else:\n",
    "                if vis:\n",
    "                    annot.set_visible(False)\n",
    "                    fig.canvas.draw_idle()\n",
    "\n",
    "    cursor = mplcursors.cursor(sc, hover=True)\n",
    "    cursor.connect(\n",
    "    \"add\", lambda sel: sel.annotation.set_text(tt[sel.index]))\n",
    "    plt.xlabel(\"semantic score\")\n",
    "    plt.ylabel(\"number of subscribers per year since first upload date\")\n",
    "    plt.show()\n",
    "\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    plt.plot(x, m*x + b)\n",
    "generate_plot(semantic_df)\n",
    "\n",
    "x= 'rescaledSubCount'\t\n",
    "y= 'positivityScores'\n",
    "result = scipy.stats.linregress(semantic_df[x], semantic_df[y])\n",
    "print(\"no outliers removed: \", 'slope: {}, rvalue:{}, pvalue:{}'.format(result.slope, round(result.rvalue, 5), round(result.pvalue, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def detect_outlier(data_1):\n",
    "    outliers=[]\n",
    "    # threshold=3 means any data with a stdDev> 3 or <-3 is 0.3 of all data. Almost all of the data (99.7%) should be within 3 stddev from the mean\n",
    "    threshold=3\n",
    "    mean_1 = np.mean(data_1)\n",
    "    std_1 =np.std(data_1)\n",
    "    \n",
    "    index =0\n",
    "    for y in data_1:\n",
    "        z_score= (y - mean_1)/std_1 \n",
    "        if np.abs(z_score) > threshold:\n",
    "            outliers.append((index, y))\n",
    "        index+=1\n",
    "    return outliers\n",
    "print(\"===========rescaledSubs outlier===========\")\n",
    "for indexToScore in detect_outlier(subsPerYearSinceFirstUpload):\n",
    "    print(\"{}:{}\".format(channelHolisticInfoDf['channelName'][indexToScore[0]], indexToScore[1]))\n",
    "print(\"===========semantic_scores outliers===========\")\n",
    "for indexToScore in detect_outlier(list(channelName_to_scores.values())):\n",
    "    print(\"{}:{}\".format(channelHolisticInfoDf['channelName'][indexToScore[0]], indexToScore[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2af795",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_df = pd.DataFrame.from_dict({'channelName': channelHolisticInfoDf['channelName'], 'rescaledSubCount': subsPerYearSinceFirstUpload, 'positivityScores': channelName_to_scores.values()})\n",
    "semantic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3656f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "copy_without_rescaledSubs_outlier = semantic_df.drop(29)\n",
    "copy_without_semantic_outlier = semantic_df.drop([28, 46, 58])\n",
    "copy_without_rescaledSubs_and_semantic_outlier = semantic_df.drop([29, 28, 46, 58])\n",
    "semantic_df_copy_without_rescaledSubs_outlier = pd.DataFrame.from_dict(json.loads(json.dumps(copy_without_rescaledSubs_outlier.to_dict())))\n",
    "semantic_df_copy_without_semantic_outlier = pd.DataFrame.from_dict(json.loads(json.dumps(copy_without_semantic_outlier.to_dict())))\n",
    "semantic_df_copy_without_rescaledSubs_and_semantic_outlier = pd.DataFrame.from_dict(json.loads(json.dumps(copy_without_rescaledSubs_and_semantic_outlier.to_dict())))\n",
    "\n",
    "x= 'rescaledSubCount'\t\n",
    "y= 'positivityScores'\n",
    "result = scipy.stats.linregress(semantic_df[x], semantic_df[y])\n",
    "result_no_rescaled_outlier = scipy.stats.linregress(semantic_df_copy_without_rescaledSubs_outlier[x], semantic_df_copy_without_rescaledSubs_outlier[y])\n",
    "result_no_semantic_outlier = scipy.stats.linregress(semantic_df_copy_without_semantic_outlier[x], semantic_df_copy_without_semantic_outlier[y])\n",
    "result_no_rescaled_and_semantic_outliers = scipy.stats.linregress(semantic_df_copy_without_rescaledSubs_and_semantic_outlier[x], semantic_df_copy_without_rescaledSubs_and_semantic_outlier[y])\n",
    "\n",
    "print(\"no outliers removed: \", 'rvalue:{}, pvalue:{}'.format(result.rvalue, result.pvalue))\n",
    "print(\"removed positivity outlier: \", 'rvalue:{}, pvalue:{}'.format(result_no_rescaled_outlier.rvalue, result_no_rescaled_outlier.pvalue))\n",
    "print(\"removed subCount outlier: \", 'rvalue:{}, pvalue:{}'.format(result_no_semantic_outlier.rvalue, result_no_semantic_outlier.pvalue))\n",
    "print(\"removed both subCount and positivity outliers: \", 'rvalue:{}, pvalue:{}'.format(result_no_rescaled_and_semantic_outliers.rvalue, result_no_rescaled_and_semantic_outliers.pvalue))\n",
    "print()\n",
    "print(\"no outliers removed: \", scipy.stats.spearmanr(semantic_df[x_name], semantic_df[y_name], axis=0))\n",
    "print(\"removed positivity outlier: \", scipy.stats.spearmanr(semantic_df_copy_without_semantic_outlier[x_name], semantic_df_copy_without_semantic_outlier[y_name], axis=0))\n",
    "print(\"removed subCount outlier: \",  scipy.stats.spearmanr(semantic_df_copy_without_rescaledSubs_outlier[x_name], semantic_df_copy_without_rescaledSubs_outlier[y_name], axis=0))\n",
    "print(\"removed both subCount and positivity outliers: \", scipy.stats.spearmanr(semantic_df_copy_without_rescaledSubs_and_semantic_outlier[x_name], semantic_df_copy_without_rescaledSubs_and_semantic_outlier[y_name], axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d40dd",
   "metadata": {},
   "source": [
    "The p (or probability) value obtained from the calculator is a measure of how likely or probable it is that any observed correlation is due to chance. P-values range between 0 (0%) and 1 (100%). A p-value close to 1 suggests no correlation other than due to chance and that your null hypothesis assumption is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec2ccd",
   "metadata": {},
   "source": [
    "So how exactly strong is the correlation? \n",
    "We use r-values\n",
    "https://www.researchgate.net/post/What-does-R-square-Adjusted-R-and-R-indicate-in-terms-of-Multiple-Regression-Analysis\n",
    "\n",
    "Simply put, R is the correlation between the predicted values and the observed values of Y. R square is the square of this coefficient and indicates the percentage of variation explained by your regression line out of the total variation. This value tends to increase as you include additional predictors in the model. Thus, one can artificially get higher  R square by increasing the number of Xs in the model. To penalize this effect, adjusted R square is used. When you compare models with their complexity, you should then rely on Adj R square. Predicted R square is another measure which addresses the issue of overfitting the data  and explain the prediction power for future observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8aabb0",
   "metadata": {},
   "source": [
    "The p (or probability) value obtained from the calculator is a measure of how likely or probable it is that any observed correlation is due to chance. P-values range between 0 (0%) and 1 (100%). A p-value close to 1 suggests no correlation other than due to chance and that your null hypothesis assumption is correct.\n",
    "\n",
    "Tbh, the results kind of suck. \n",
    "Need to test the null hypothesis\n",
    "The null hypothesis is a typical statistical theory which suggests that **no statistical relationship and significance exists in a set of given single observed variable**, between two sets of observed data and measured phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e571fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjR(x, y, degree):\n",
    "    results = {}\n",
    "    coeffs = np.polyfit(x, y, degree)\n",
    "    p = np.poly1d(coeffs)\n",
    "    yhat = p(x)\n",
    "    ybar = np.sum(y)/len(y)\n",
    "    ssreg = np.sum((yhat-ybar)**2)\n",
    "    sstot = np.sum((y - ybar)**2)\n",
    "    results['r_squared'] = 1- (((1-(ssreg/sstot))*(len(y)-1))/(len(y)-degree-1))\n",
    "\n",
    "    return results\n",
    "\n",
    "for i in range(5):\n",
    "    print(adjR(semantic_df[x], semantic_df[y], i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430e1ef",
   "metadata": {},
   "source": [
    "! https://opentextbc.ca/researchmethods/chapter/understanding-null-hypothesis-testing/\n",
    "A crucial step in null hypothesis testing is finding the likelihood of the sample result if the null hypothesis were true. This probability is called the p value. A low p value means that the sample result would be unlikely if the null hypothesis were true and leads to the rejection of the null hypothesis. A high p value means that the sample result would be likely if the null hypothesis were true and leads to the retention of the null hypothesis. But how low must the p value be before the sample result is considered unlikely enough to reject the null hypothesis? In null hypothesis testing, this criterion is called α (alpha) and is almost always set to .05. If there is less than a 5% chance of a result as extreme as the sample result if the null hypothesis were true, then the null hypothesis is rejected. When this happens, the result is said to be statistically significant. If there is greater than a 5% chance of a result as extreme as the sample result when the null hypothesis is true, then the null hypothesis is retained. This does not necessarily mean that the researcher accepts the null hypothesis as true—only that there is not currently enough evidence to conclude that it is true. Researchers often use the expression “fail to reject the null hypothesis” rather than “retain the null hypothesis,” but they never use the expression “accept the null hypothesis.”\n",
    "\n",
    "> The Misunderstood p Value\n",
    "\n",
    "> The p value is one of the most misunderstood quantities in psychological research (Cohen, 1994)[1]. Even professional researchers misinterpret it, and it is not unusual for such misinterpretations to appear in statistics textbooks!\n",
    "\n",
    "> The most common misinterpretation is that the p value is the probability that the null hypothesis is true—that the sample result occurred by chance. For example, a misguided researcher might say that because the p value is .02, there is only a 2% chance that the result is due to chance and a 98% chance that it reflects a real relationship in the population. But this is incorrect. The p value is really the probability of a result at least as extreme as the sample result if the null hypothesis were true. So a p value of .02 means that if the null hypothesis were true, a sample result this extreme would occur only 2% of the time.\n",
    "\n",
    "> You can avoid this misunderstanding by remembering that the p value is not the probability that any particular hypothesis is true or false. Instead, it is the probability of obtaining the sample result if the null hypothesis were true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c47efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ace.samples import wang04\n",
    "x, y = wang04.build_sample_ace_problem_wang04(N=200)\n",
    "print(len(x), len(x[0]), len(y))\n",
    "from ace import model\n",
    "myace = model.Model()\n",
    "myace.build_model_from_xy(x, y)\n",
    "myace.eval([0.1, 0.2, 0.5, 0.3, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6599b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ace import model\n",
    "x= 'rescaledSubCount'\t\n",
    "y= 'positivityScores'\n",
    "myace = model.Model()\n",
    "myace.build_model_from_xy([semantic_df[x]], semantic_df[y])\n",
    "myace.eval([0.0001])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "811149f64e05d2226278a2e375973a70398b68aeeea8a4c51891bf9fc1d57f5b"
  },
  "kernelspec": {
   "display_name": "Python [conda env:colorization]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
