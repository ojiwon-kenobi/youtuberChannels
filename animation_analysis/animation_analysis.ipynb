{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47e2708",
   "metadata": {},
   "source": [
    "We extract video frames from selected animations and extract\n",
    "the line art images to form our training dataset. We calculate a\n",
    "**768-dimensional feature vector of histograms of R, G, B channels\n",
    "for each frame**. The difference between frames is determined by\n",
    "calculating the **mean square error** of the feature vectors, which\n",
    "is used for splitting the source animations into shots. When the\n",
    "difference between the neighboring frames is **greater than 200**, it\n",
    "is considered to belong to different shots. In order to improve the\n",
    "quality of the data, we **remove shots in which the mean square\n",
    "errors between all pairs of frames are less than 10** (as they are\n",
    "too uniform), and **the shot with a length less than 8 frames**.\n",
    "Then we **filter out video frames that are too dark or too faded\n",
    "in color**. Finally we get a total of \n",
    "1096 video sequences from 6 animations, with a total of 29,834 images. \n",
    "Each video sequence\n",
    "has 27 frames on average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "269c5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9eff60",
   "metadata": {},
   "source": [
    "Let's create the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4bb7a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "29 640 360\n",
      "11453 frames in file\n",
      "True\n",
      "25 640 360\n",
      "27641 frames in file\n",
      "True\n",
      "29 640 360\n",
      "16502 frames in file\n",
      "True\n",
      "29 640 360\n",
      "9485 frames in file\n",
      "True\n",
      "24 640 360\n",
      "11420 frames in file\n"
     ]
    }
   ],
   "source": [
    "def VidToFrames (vidpath, folderName):\n",
    "    vidcap = cv2.VideoCapture(vidpath)\n",
    "    success,image = vidcap.read()\n",
    "    print(success)\n",
    "    count = 0\n",
    "    length = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "    width  = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(length, width, height)\n",
    "    while success:\n",
    "        cv2.imwrite(\"{foldername}/{frameNum}.png\".format(foldername= folderName, frameNum=str(count)), image)  \n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "    print(count, \"frames in file\")\n",
    "\n",
    "# for i in glob.glob(\"../mp4/*.mp4\"):\n",
    "for i in glob.glob(\"../mp4/*.mp4\"):\n",
    "    destination = i.split('.mp4')[0]\n",
    "    os.mkdir(destination)\n",
    "    VidToFrames(i, destination)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44fd142",
   "metadata": {},
   "source": [
    "Now that we have folders with frames from each video for each channelId, we can start the analysis. There is two parts to this: \n",
    "1. Color analysis\n",
    "2. Motion analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b53a8c",
   "metadata": {},
   "source": [
    "### Part I  <br/>\n",
    "***Color Analysis*** <br/>\n",
    "Is there a correlation between color and subcount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6741092d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "def removeDimAndFadedImages(folderName):\n",
    "    sortedFrameList = sorted(glob.glob(folderName+'/*.png'), key=os.path.getmtime)\n",
    "    debugCount = 0\n",
    "    for imagePath in sortedFrameList:\n",
    "        brightness = getBrightnessOfImage(imagePath)\n",
    "        if brightness < 9.4e7 or brightness > 4.5e8: # brightness < 6*10^7 or brightness > 7*10^8:\n",
    "            print(imagePath, \": \", brightness)\n",
    "            os.remove(imagePath)\n",
    "        if debugCount % 100 == 0: \n",
    "            print (debugCount)\n",
    "        debugCount +=1\n",
    "\n",
    "        \n",
    "def getBrightnessOfImage(imagePath):\n",
    "    image = cv2.imread(imagePath)\n",
    "    vectors = []\n",
    "    for i, col in enumerate(['b', 'g', 'r']):\n",
    "        hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "        sums = np.sum(np.fromiter((index*hist[index] for index in range(len(hist))), dtype=float))\n",
    "        vectors.append(sums)\n",
    "        plt.plot(hist, color = col)\n",
    "        plt.xlim([0, 256])\n",
    "    plt.show()\n",
    "    totalSums = np.sum(vectors)\n",
    "    return totalSums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc3d39",
   "metadata": {},
   "source": [
    "An image histogram gives a graphical representation of the distribution of pixel intensities in a digital image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "06d87ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binAndPlot(some_list):\n",
    "    sorted_list = sorted(some_list)\n",
    "    sorted_counted = Counter(sorted_list)\n",
    "    range_length = list(range(int(max(some_list)+1))) # Get the largest value to get the range.\n",
    "    data_series = {}\n",
    "\n",
    "    for i in range_length:\n",
    "        data_series[i] = 0 # Initialize series so that we have a template and we just have to fill in the values.\n",
    "    for key, value in sorted_counted.items():\n",
    "        data_series[key] = value\n",
    "    data_series = pd.Series(data_series)\n",
    "    x_values = data_series.index\n",
    "    plt.hist(some_list, edgecolor=\"yellow\", color=\"green\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc523e0",
   "metadata": {},
   "source": [
    "### Part 2:\n",
    "*** Motion Analysis ***\n",
    "\n",
    "Is there a correlation between the amount of animation and subcount?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea390b8",
   "metadata": {},
   "source": [
    "In my head, I should technically analyze how much each frame differs from each other. \n",
    "However, color is a value that is assigned to each pixel in a frame.\n",
    "\n",
    "So we are going to get rid of color. We're not completely getting rid of it tho- any changes due to color will be detected (example)- because we are using\n",
    "ahem ahem an eXtended difference-of-Gaussians to extract the lines. So we're basically changing the data to put less weight on color because it's already been accounted for in Part I."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d48e7e",
   "metadata": {},
   "source": [
    " There was a time when I was interested in colorization machine learning techniques. Honestly, I still am, just less than this project. \n",
    "\n",
    " There was a paper called [Deep Line Art Video Colorization with a Few References](https://arxiv.org/abs/2003.10685) that I spent some time generating data for. It was only after I generated all the data that I realized I don't have the resources (GPU, money, honestly, motivation was the biggest factor)\n",
    "\n",
    "> We extract video frames from selected animations and extract\n",
    "the line art images to form our training dataset. We calculate a\n",
    "768-dimensional feature vector of histograms of R, G, B channels\n",
    "for each frame. The difference between frames is determined by\n",
    "calculating the mean square error of the feature vectors, which\n",
    "is used for splitting the source animations into shots. When the\n",
    "difference between the neighboring frames is greater than 200, it\n",
    "is considered to belong to different shots. In order to improve the\n",
    "quality of the data, we remove shots in which the mean square\n",
    "errors between all pairs of frames are less than 10 (as they are\n",
    "too uniform), and the shot with a length less than 8 frames.\n",
    "Then we filter out video frames that are too dark or too faded\n",
    "in color. Finally we get a total of 1096 video sequences from 6\n",
    "animations, with a total of 29,834 images. Each video sequence\n",
    "has 27 frames on average. \n",
    "\n",
    "In my case, I got around 28k iumages with 32 frames per scene on average.\n",
    "\n",
    "I'm going to use the data collection method stated above, with a slight variation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "164783cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "with open('../channelId_to_mostViewedVidId.json', 'r') as j:\n",
    "    channelId_to_mostViewedVidId = json.loads(j.read())\n",
    "\n",
    "LIST_OF_CHANNEL_IDS= channelId_to_mostViewedVidId.keys()\n",
    "print(len(LIST_OF_CHANNEL_IDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../masterSheet.json', 'r') as j:\n",
    "    masterSheet = json.loads(j.read())\n",
    "\n",
    "channelId_to_mostViewedVidInfo = {}\n",
    "\n",
    "for channelId in LIST_OF_CHANNEL_IDS:\n",
    "    mostViewedVidId = channelId_to_mostViewedVidId[channelId]\n",
    "    for vidInfo in masterSheet[channelId]:\n",
    "        if vidInfo['vidId'] == mostViewedVidId:\n",
    "            channelId_to_mostViewedVidInfo[channelId] = vidInfo\n",
    "channelId_to_mostViewedVidInfo\n",
    "# print(len(channelId_to_mostViewedVidId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cc4bc1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KwkhpOJ6nQ4', 'I9uWUw1fxOY', 'uDvPIKM-L1o', '5pMckBGWzAY', 'cZ_CnLE6SPo', 'Hkz0NcKPzMs', 'eNGgfPs0Xp8', '6wS_uON5s6Q', 'kQEtRoyFfI8', 'ewsGmhAjjjI', 'Ln4AnsWNUQI', 'Xnv7JGqjaAo', 'Ox49X6Andl8', 'IwxWmKsVR5U', 'iRBmUQQzpWQ', 'F8A-tXp09fs', 'oKLbOxLJfRg', '7FnQrNFyWy8', 'gA0bi-bFEYs', 'xa-4IAR_9Yw', 'P2EjH7l_N70', 'vv2vPAzj8S4', 'RlU32AfEVeU', 'WXNmSruTWIA', 'vuk2NZ0YKAE', '_uk_6vfqwTA', 'W8P5ewPk9fM', '7WSo1Uw-p_g', '12Ne9n40tmw', '2E2El1kdooM', 'EcgkRp2IUsc', 'O0hyjRF6quc', 'BErOLQBZ6c8', 'de8PRd_d7kg', 'so1_5hYUEE8', '0Vxp_Lj2b-E', 'rnQlkpOFgm8', 'uqJKryP1-8M', '2bGkEK8I6zQ', 'OyDLuom4KGs', 'Y7lYeRqhQ9Q', '18msRdBF11A', '2juKkLxdQo0', '0TlV3w1YGqk', 'o0zjRGRYEhk', 'hpQQohcHk9Q', 'PgajWuZA408', 'Vm6Yu2N-ePI', '2yFCyPX3kT0', 'EZCfJqr7Eao', 'nHgRnjqLmtM', 'plSyrHqUh78', 'iVqhzEaJhDw', 'LdNi3PpGtl8', 'n4CAhXpyVCI', 'Mv8OkBjySGQ', 'kbCah6yhYRs', 'A6V1QujNz8s', 'iEW-d02l9ew', '9oUpImsyf4Y', 'rlSXaDq3uOk'}\n",
      "{'Ln4AnsWNUQI', 'KwkhpOJ6nQ4', 'I9uWUw1fxOY', 'xa-4IAR_9Yw', 'EZCfJqr7Eao', 'iVqhzEaJhDw', 'Hkz0NcKPzMs', 'RlU32AfEVeU', 'LdNi3PpGtl8', '6wS_uON5s6Q', 'kQEtRoyFfI8', '18msRdBF11A', '12Ne9n40tmw', 'Xnv7JGqjaAo', 'Ox49X6Andl8', 'iEW-d02l9ew', 'hpQQohcHk9Q'}\n",
      "['5pMckBGWzAY', 'cZ_CnLE6SPo', 'eNGgfPs0Xp8', 'ewsGmhAjjjI', 'A6V1QujNz8s', 'IwxWmKsVR5U', 'iRBmUQQzpWQ', 'F8A-tXp09fs', 'oKLbOxLJfRg', '7FnQrNFyWy8', 'gA0bi-bFEYs', 'P2EjH7l_N70', 'vv2vPAzj8S4', 'WXNmSruTWIA', 'vuk2NZ0YKAE', '_uk_6vfqwTA', 'W8P5ewPk9fM', '7WSo1Uw-p_g', '2E2El1kdooM', 'EcgkRp2IUsc', 'O0hyjRF6quc', 'BErOLQBZ6c8', 'de8PRd_d7kg', 'so1_5hYUEE8', '0Vxp_Lj2b-E', 'rnQlkpOFgm8', 'uqJKryP1-8M', '2bGkEK8I6zQ', 'OyDLuom4KGs', 'Y7lYeRqhQ9Q', '2juKkLxdQo0', '0TlV3w1YGqk', 'o0zjRGRYEhk', 'PgajWuZA408', 'Vm6Yu2N-ePI', '2yFCyPX3kT0', 'nHgRnjqLmtM', 'plSyrHqUh78', 'n4CAhXpyVCI', 'Mv8OkBjySGQ', 'kbCah6yhYRs', 'uDvPIKM-L1o', '9oUpImsyf4Y', 'rlSXaDq3uOk']\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "df = pandas.DataFrame.from_dict(channelId_to_mostViewedVidInfo).T\n",
    "not_candidate_vidIds= ['kQEtRoyFfI8', 'hpQQohcHk9Q', '6wS_uON5s6Q', 'RlU32AfEVeU', 'iVqhzEaJhDw', 'Xnv7JGqjaAo', '18msRdBF11A', 'Ln4AnsWNUQI', 'Hkz0NcKPzMs']\n",
    "\n",
    "#https://en.wikipedia.org/wiki/ISO_8601#Durations\n",
    "for channelId, row in df.iterrows():\n",
    "    x= row['duration']\n",
    "    m=0\n",
    "    s=0\n",
    "    try:\n",
    "        m, s = re.findall('PT(\\d+)M(\\d+)S',x)[0]\n",
    "    except:\n",
    "        s = re.findall('PT(\\d+)S',x)[0]\n",
    "    if int(m)*60+int(s) < 180:\n",
    "        not_candidate_vidIds.append(row['vidId'])\n",
    "not_candidate_vidIds = set(not_candidate_vidIds)\n",
    "candidateVideos = list(set(df.vidId)- not_candidate_vidIds)\n",
    "df = df[df.vidId.isin(candidateVideos)]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0eb7f7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames/Private School-IwxWmKsVR5U\n",
      "[lineart]Private School-IwxWmKsVR5U/\n",
      "11453 out of 11453  files converted to lineart\n",
      "frames/Embarrassing Water Park Story (Ft. Emirichu)-P2EjH7l_N70\n",
      "[lineart]Embarrassing Water Park Story (Ft. Emirichu)-P2EjH7l_N70/\n",
      "16502 out of 16502  files converted to lineart\n",
      "frames/Life is Fun - TheOdd1sOut - Animation Breakdown-Xnv7JGqjaAo\n",
      "[lineart]Life is Fun - TheOdd1sOut - Animation Breakdown-Xnv7JGqjaAo/\n",
      "9485 out of 9485  files converted to lineart\n",
      "frames/How I Met My 'Boyfriend' (ft. Sultan Sketches)-vv2vPAzj8S4\n",
      "[lineart]How I Met My 'Boyfriend' (ft. Sultan Sketches)-vv2vPAzj8S4/\n",
      "4117 out of 4117  files converted to lineart\n",
      "frames/Can They Survive My Hero Academia-2bGkEK8I6zQ\n",
      "[lineart]Can They Survive My Hero Academia-2bGkEK8I6zQ/\n",
      "27641 out of 27641  files converted to lineart\n"
     ]
    }
   ],
   "source": [
    "def ColorToLineart (framepath):\n",
    "    lineartpath = \"[lineart]\"+ framepath.split('/')[-1]+\"/\"\n",
    "    os.mkdir(lineartpath)\n",
    "    print(lineartpath)\n",
    "    imgList = glob.glob('%s/*'% framepath)\n",
    "    count=0\n",
    "    for i in imgList:\n",
    "        try:\n",
    "            xdog2(i, lineartpath)\n",
    "            count+=1\n",
    "        except:\n",
    "            print(lineartpath)\n",
    "    print(count, \"out of\", len(imgList), \" files converted to lineart\")\n",
    "    \n",
    "for framepath in glob.glob(\"frames/*\"):\n",
    "    print(framepath)\n",
    "    ColorToLineart(framepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "587df353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XDoG\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "def xdog(original, count, lineartPath, epsilon=0.5, phi=10, k=1.4, tau=1, sigma=0.5):\n",
    "    image = cv2.imread(original, cv2.IMREAD_GRAYSCALE)\n",
    "    image = gaussian_filter(image, 0.7)\n",
    "    gauss1 = gaussian_filter(image, sigma)\n",
    "    gauss2 = gaussian_filter(image, sigma*k)\n",
    "\n",
    "    D = gauss1 - tau*gauss2\n",
    "\n",
    "    U = D/255\n",
    "    \n",
    "    for i in range(0,len(U)):\n",
    "        for j in range(0,len(U[0])):\n",
    "            U[i][j] = abs(1-U[i][j])\n",
    "    for i in range(0, len(U)):\n",
    "        for j in range(0, len(U[0])):\n",
    "            if U[i][j] >= epsilon:\n",
    "                U[i][j] = 1\n",
    "            else:\n",
    "                ht = np.tanh(phi*(U[i][j] - epsilon))\n",
    "                U[i][j] = 1 + ht\n",
    "\n",
    "    lineart = U*255\n",
    "    success = cv2.imwrite(lineartPath+\"/%d.png\" % count, lineart)\n",
    "\n",
    "def dodgeV2(x, y):\n",
    "    return cv2.divide(x, 255 - y, scale=256)\n",
    "\n",
    "def xdog2 (original, lineartPath):\n",
    "    img = cv2.imread(original)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_invert = cv2.bitwise_not(img_gray)\n",
    "    img_smoothing = cv2.GaussianBlur(img_invert, (21, 21),sigmaX=0, sigmaY=0)\n",
    "    final_img = dodgeV2(img_gray, img_smoothing)\n",
    "\n",
    "    success = cv2.imwrite(lineartPath+original.split('/')[-1], final_img)     # save frame as JPEG file      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3197d2",
   "metadata": {},
   "source": [
    "Get lineart for all frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec6a3b",
   "metadata": {},
   "source": [
    "couple that do not fit the criteria:: vidIds [kQEtRoyFfI8- gameplay, hpQQohcHk9Q- too short. not commentary, 6wS_uON5s6Q- speeddrawing, RlU32AfEVeU- footage apparently from another youtuber, iVqhzEaJhDw- too short, Xnv7JGqjaAo- speeddraw, iRBmUQQzpWQ- simply not animation, 18msRdBF11A- not animation, Ln4AnsWNUQI- not animation, Hkz0NcKPzMs- too short]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb5ecb",
   "metadata": {},
   "source": [
    "The plan is to find the distribution of DIFF. It'll vary based on the artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "edc7770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames/lineart/[lineart]i was gonna delete this but you guys told me not to-iVqhzEaJhDw\n",
      "60 out of 1129 files were duplicates\n",
      "DIFF min:  0.0  max:  94.05469 mean:  8.618614 \n",
      "MSE min:  0.0  max:  637.0105555555556 mean:  4.005593286729216 \n",
      "===============================================================================\n",
      "frames/lineart/[lineart]Being a Boba Barista (Work Stories)-so1_5hYUEE8\n",
      "6263 out of 9584 files were duplicates\n",
      "DIFF min:  0.0  max:  1800.0 mean:  5.462136 \n",
      "MSE min:  0.0  max:  460080.9244444444 mean:  111.91795814184115 \n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def getFeatureVectorOfImage_color (imagePath):\n",
    "    image = cv2.imread(imagePath)\n",
    "    vectors = []\n",
    "    for i, col in enumerate(['b', 'g', 'r']):\n",
    "        hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "        vectors.append(hist)\n",
    "        # plt.plot(hist, color = col)\n",
    "        # plt.xlim([0, 256])\n",
    "    # plt.show()\n",
    "    vectors = np.vstack(vectors)\n",
    "    return vectors\n",
    "\n",
    "def getFeatureVectorOfImage (imagePath):\n",
    "    image = cv2.imread(imagePath)\n",
    "    vectors = []\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    vectors = np.vstack(hist)\n",
    "    return vectors\n",
    "\n",
    "def MSE_images (vA, vB):\n",
    "    return np.sum(np.square(np.subtract(vA, vB)))\n",
    "\n",
    "def DIFF_images(vA, vB):\n",
    "    return (np.abs(vA - vB)).mean()\n",
    "\n",
    "def removeLowDiff_andDemo(folderName):\n",
    "    print(folderName)\n",
    "    lenOfFrameList = len(glob.glob(glob.escape(folderName)+'/*.png')) #unfortunately, doesn't work bc sortByInt isn't a thing\n",
    "    filesMoved = 0 \n",
    "    validFrameList = []\n",
    "\n",
    "    lowRangeDone= False\n",
    "    midRangeDone= False\n",
    "    highRangeDone= False\n",
    "\n",
    "    listOfMSE = []\n",
    "    listOfDIFF = []\n",
    "\n",
    "    imageShape = cv2.imread('{}/{}.png'.format(folderName, 0)).shape\n",
    "    h,w,c = imageShape\n",
    "    for i in range(lenOfFrameList-1):\n",
    "        firstFrame = '{}/{}.png'.format(folderName, i)\n",
    "        secondFrame = '{}/{}.png'.format(folderName, i+1)\n",
    "        f1_v = getFeatureVectorOfImage(firstFrame)\n",
    "        f2_v = getFeatureVectorOfImage(secondFrame)\n",
    "        diff = DIFF_images(f1_v, f2_v)\n",
    "        mse = MSE_images(f1_v, f2_v)/ (h*w)\n",
    "        listOfDIFF.append(diff)\n",
    "        listOfMSE.append(mse)\n",
    "\n",
    "        if (diff >= 2):\n",
    "            validFrameList.append(firstFrame)\n",
    "            filesMoved+=1\n",
    "        # if (lowRangeDone and midRangeDone and highRangeDone) == False:\n",
    "        #     if (diff == 0 and not lowRangeDone):\n",
    "        #         print (\"low diff = : \", diff)\n",
    "        #         print(firstFrame)\n",
    "        #         display(Image(filename=firstFrame))\n",
    "        #         print (secondFrame)\n",
    "        #         display(Image(filename=secondFrame))\n",
    "        #         lowRangeDone = True\n",
    "        #     if (diff > 100 and diff < 150  and not midRangeDone):\n",
    "        #         print (\"mid diff = : \", diff)\n",
    "        #         print(firstFrame)\n",
    "        #         display(Image(filename=firstFrame))\n",
    "        #         print (secondFrame)\n",
    "        #         display(Image(filename=secondFrame))\n",
    "        #         midRangeDone = True\n",
    "        #     if (diff > 250 and diff < 300  and not highRangeDone):\n",
    "        #         print (\"high diff = : \", diff)\n",
    "        #         print(firstFrame)\n",
    "        #         display(Image(filename=firstFrame))\n",
    "        #         print (secondFrame)\n",
    "        #         display(Image(filename=secondFrame))\n",
    "        #         highRangeDone = True\n",
    "    print(lenOfFrameList - filesMoved, \"out of\", lenOfFrameList, \"files were duplicates\")\n",
    "    # binAndPlot(listOfDIFF)\n",
    "    print(\"DIFF min: \", np.amin(listOfDIFF), \" max: \", np.amax(listOfDIFF), \"mean: \", np.mean(listOfDIFF), \"\")\n",
    "    # binAndPlot(listOfMSE)\n",
    "    print(\"MSE min: \", np.amin(listOfMSE), \" max: \", np.amax(listOfMSE), \"mean: \", np.mean(listOfMSE), \"\")\n",
    "\n",
    "    return validFrameList\n",
    "            \n",
    "\n",
    "for lineartPath in glob.glob(\"frames/lineart/*\")[3:5]:\n",
    "    removeLowDiffDst = removeLowDiff_andDemo(lineartPath)\n",
    "    print(\"===============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6e0cce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectScenes(folderName, diff):\n",
    "    with open(folderName+\"_sceneDetection.txt\", 'w') as f:\n",
    "        sortedFrameList = sorted(glob.glob(folderName+'*.png'), key=os.path.getmtime)\n",
    "        startOfShot=0\n",
    "        numberOfScenes = 0\n",
    "        lengthOfScene = 0\n",
    "        for index in len(sortedFrameList-1):\n",
    "            if MSE_images(sortedFrameList[index], sortedFrameList[index+1]) > diff:\n",
    "                if lengthOfScene > 8:\n",
    "                    f.write(startOfShot, \", \", index)\n",
    "                    numberOfScenes += 1\n",
    "                startOfShot = index+1\n",
    "                lengthOfScene = 0\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "811149f64e05d2226278a2e375973a70398b68aeeea8a4c51891bf9fc1d57f5b"
  },
  "kernelspec": {
   "display_name": "Python [conda env:colorization]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
